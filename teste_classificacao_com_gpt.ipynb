{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f90dc529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2357e6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ A chave está funcionando!\n",
      "Resposta: funcionando\n"
     ]
    }
   ],
   "source": [
    "client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "try:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-2024-08-06\",\n",
    "        messages=[{\"role\": \"user\", \"content\": \"Diga apenas: funcionando\"}],\n",
    "        max_tokens=5\n",
    "    )\n",
    "    print(\"✔ A chave está funcionando!\")\n",
    "    print(\"Resposta:\", response.choices[0].message.content)\n",
    "except Exception as e:\n",
    "    print(\"✘ Erro! A chave NÃO está funcionando.\")\n",
    "    print(\"Detalhes:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b910b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email = pd.read_csv('./email.csv')\n",
    "email.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00104683",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_email = email.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "113e4ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_respostas = []\n",
    "sample_email = email.sample(100)\n",
    "\n",
    "for message in sample_email['Message']:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-2024-08-06\",\n",
    "        messages=[{\"role\": \"user\", \"content\": \"Você é um especialista em detecção de spam. Analise a seguinte mensagem e diga se é spam ou não, sendd 1 para spam e 0 para não. Não responsa nada mais além disso: \" + message}],\n",
    "        max_tokens=5\n",
    "    )\n",
    "\n",
    "    resposta = response.choices[0].message.content.strip()\n",
    "    lista_respostas.append(resposta)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83df47bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "      <th>Category_GPT4O</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3481</th>\n",
       "      <td>ham</td>\n",
       "      <td>What was she looking for?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>ham</td>\n",
       "      <td>What your plan for pongal?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>ham</td>\n",
       "      <td>I cant keep talking to people if am not sure i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3575</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yeah sure I'll leave in a min</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category                                            Message  \\\n",
       "1485      ham                             Sorry, I'll call later   \n",
       "3481      ham                          What was she looking for?   \n",
       "1255      ham                         What your plan for pongal?   \n",
       "374       ham  I cant keep talking to people if am not sure i...   \n",
       "3575      ham                      Yeah sure I'll leave in a min   \n",
       "\n",
       "     Category_GPT4O  \n",
       "1485              0  \n",
       "3481              0  \n",
       "1255              0  \n",
       "374               0  \n",
       "3575              0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_email['Category_GPT4O'] = lista_respostas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f0bba87",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_email['Category_int'] = sample_email['Category'].apply(lambda x: 1 if x == 'spam' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01d9b059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.80\n",
      "Recall: 1.00\n",
      "F1 Score: 0.89\n",
      "Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "# metrics \n",
    "\n",
    "precision = precision_score(sample_email['Category_int'], sample_email['Category_GPT4O'].astype(int))\n",
    "recall = recall_score(sample_email['Category_int'], sample_email['Category_GPT4O'].astype(int))\n",
    "f1 = f1_score(sample_email['Category_int'], sample_email['Category_GPT4O'].astype(int))\n",
    "accuracy = accuracy_score(sample_email['Category_int'], sample_email['Category_GPT4O'].astype(int))\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a50b91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeiras linhas do dataset:\n",
      "  Category                                            Message\n",
      "0      ham  Go until jurong point, crazy.. Available only ...\n",
      "1      ham                      Ok lar... Joking wif u oni...\n",
      "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3      ham  U dun say so early hor... U c already then say...\n",
      "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
      "\n",
      "Tamanho do conjunto usado:\n",
      "5573\n",
      "\n",
      "===== FOLD 1/5 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xd-bo\\Desktop\\projects\\-UFJF-MS-Computer-Science---Machine-Learning-Work-Spam-Detection-\\venv\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9534\n",
      "Precision: 0.7526\n",
      "Recall:    0.9733\n",
      "F1-score:  0.8488\n",
      "\n",
      "===== FOLD 2/5 =====\n",
      "Accuracy:  0.9480\n",
      "Precision: 0.7255\n",
      "Recall:    0.9867\n",
      "F1-score:  0.8362\n",
      "\n",
      "===== FOLD 3/5 =====\n",
      "Accuracy:  0.9498\n",
      "Precision: 0.7313\n",
      "Recall:    0.9866\n",
      "F1-score:  0.8400\n",
      "\n",
      "===== FOLD 4/5 =====\n",
      "Accuracy:  0.9479\n",
      "Precision: 0.7310\n",
      "Recall:    0.9664\n",
      "F1-score:  0.8324\n",
      "\n",
      "===== FOLD 5/5 =====\n",
      "Accuracy:  0.9470\n",
      "Precision: 0.7228\n",
      "Recall:    0.9799\n",
      "F1-score:  0.8319\n",
      "\n",
      "===== MÉDIAS FINAIS (GPT com K-Fold) =====\n",
      "Accuracy médio:  0.9492\n",
      "Precision média: 0.7326\n",
      "Recall médio:    0.9786\n",
      "F1-score médio:  0.8379\n",
      "\n",
      "Primeiras linhas com previsão do GPT:\n",
      "  Category                                            Message Category_GPT\n",
      "0      ham  Go until jurong point, crazy.. Available only ...          ham\n",
      "1      ham                      Ok lar... Joking wif u oni...          ham\n",
      "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...         spam\n",
      "3      ham  U dun say so early hor... U c already then say...          ham\n",
      "4      ham  Nah I don't think he goes to usf, he lives aro...          ham\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 0. IMPORTS\n",
    "# ============================================================\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. FUNÇÃO: CLASSIFICAR UMA ÚNICA MENSAGEM COM GPT\n",
    "# ============================================================\n",
    "\n",
    "def classify_with_gpt(message: str, model_name: str = \"gpt-4o-2024-08-06\") -> str:\n",
    "    \"\"\"\n",
    "    Usa o GPT para classificar uma mensagem de e-mail como 'spam' ou 'ham'.\n",
    "    Retorna SEMPRE 'spam' ou 'ham' (em minúsculo).\n",
    "    \"\"\"\n",
    "    if not isinstance(message, str):\n",
    "        message = str(message)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Você é um especialista em detecção de spam.\n",
    "\n",
    "Sua tarefa é classificar a mensagem abaixo como:\n",
    "- \"spam\" se for uma mensagem indesejada, promocional, fraude, sorteio, etc.\n",
    "- \"ham\" se for uma mensagem legítima, pessoal, profissional ou neutra.\n",
    "\n",
    "Regras IMPORTANTES:\n",
    "- Responda APENAS com UMA palavra: spam ou ham.\n",
    "- Não escreva explicações.\n",
    "- Não traduza.\n",
    "- Não use frases adicionais.\n",
    "\n",
    "Mensagem:\n",
    "\\\"\\\"\\\"{message}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=3,\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    resp = response.choices[0].message.content.strip().lower()\n",
    "\n",
    "    # Normalização da resposta\n",
    "    if \"spam\" in resp and \"ham\" not in resp:\n",
    "        return \"spam\"\n",
    "    if \"ham\" in resp and \"spam\" not in resp:\n",
    "        return \"ham\"\n",
    "\n",
    "    # fallback: se ele inventar moda, consideramos ham (conservador)\n",
    "    return \"ham\"\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. CARREGAR O DATASET\n",
    "# ============================================================\n",
    "\n",
    "# Ajuste o caminho se necessário\n",
    "email = pd.read_csv(\"./email.csv\")\n",
    "\n",
    "# Normaliza colunas\n",
    "email[\"Category\"] = email[\"Category\"].astype(str).str.lower().str.strip()\n",
    "email[\"Message\"] = email[\"Message\"].astype(str)\n",
    "\n",
    "print(\"Primeiras linhas do dataset:\")\n",
    "print(email.head())\n",
    "\n",
    "# OPCIONAL: usar uma amostra para reduzir custo e tempo\n",
    "# (descomente se quiser)\n",
    "# email = email.sample(200, random_state=42).reset_index(drop=True)\n",
    "\n",
    "X = email[\"Message\"].reset_index(drop=True)\n",
    "y = email[\"Category\"].reset_index(drop=True)\n",
    "\n",
    "print(\"\\nTamanho do conjunto usado:\")\n",
    "print(len(X))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. K-FOLD USANDO APENAS GPT COMO CLASSIFICADOR\n",
    "# ============================================================\n",
    "\n",
    "k = 5  # número de folds\n",
    "\n",
    " = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# para guardar todas as previsões (mesmo índice de X/y)\n",
    "all_preds = pd.Series(index=X.index, dtype=object)\n",
    "\n",
    "accs, precs, recs, f1s = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(skf.split(X, y), 1):\n",
    "    print(f\"\\n===== FOLD {fold}/{k} =====\")\n",
    "\n",
    "    X_test = X.iloc[test_idx]\n",
    "    y_test = y.iloc[test_idx]\n",
    "\n",
    "    fold_preds = []\n",
    "\n",
    "    for msg in X_test:\n",
    "        pred = classify_with_gpt(msg)   # <<< SOMENTE GPT AQUI\n",
    "        fold_preds.append(pred)\n",
    "\n",
    "    fold_preds = np.array(fold_preds)\n",
    "    all_preds.iloc[test_idx] = fold_preds\n",
    "\n",
    "    # converte para binário (spam = 1, ham = 0) para métricas numéricas\n",
    "    y_true_bin = (y_test == \"spam\").astype(int)\n",
    "    y_pred_bin = (fold_preds == \"spam\").astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_true_bin, y_pred_bin)\n",
    "    prec = precision_score(y_true_bin, y_pred_bin, zero_division=0)\n",
    "    rec = recall_score(y_true_bin, y_pred_bin, zero_division=0)\n",
    "    f1 = f1_score(y_true_bin, y_pred_bin, zero_division=0)\n",
    "\n",
    "    accs.append(acc)\n",
    "    precs.append(prec)\n",
    "    recs.append(rec)\n",
    "    f1s.append(f1)\n",
    "\n",
    "    print(f\"Accuracy:  {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall:    {rec:.4f}\")\n",
    "    print(f\"F1-score:  {f1:.4f}\")\n",
    "\n",
    "# MÉDIAS FINAIS\n",
    "print(\"\\n===== MÉDIAS FINAIS (GPT com K-Fold) =====\")\n",
    "print(f\"Accuracy médio:  {np.mean(accs):.4f}\")\n",
    "print(f\"Precision média: {np.mean(precs):.4f}\")\n",
    "print(f\"Recall médio:    {np.mean(recs):.4f}\")\n",
    "print(f\"F1-score médio:  {np.mean(f1s):.4f}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. OPCIONAL: SALVAR RESULTADOS (RÓTULO REAL + RÓTULO GPT)\n",
    "# ============================================================\n",
    "\n",
    "email_result = email.copy().reset_index(drop=True)\n",
    "email_result[\"Category_GPT\"] = all_preds.values\n",
    "\n",
    "print(\"\\nPrimeiras linhas com previsão do GPT:\")\n",
    "print(email_result.head())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
